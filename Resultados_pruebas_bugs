Creo que la red hace overfitting: se pueden ver picos en la función de pérdida de las pruebas en las que el modelo solo empezaba a entrenar
cuando ya tenía todo el dataset. Otra opción es que en vez de ser overfitting la actualización de la red haga que cambie el TD target y entonces aumente la diferencia entre este y el valor predicho, aumentando de esta forma la pérdida.

En la prueba de 1000 samples en la que empieza a entrenar desde el principio, se pueden ver al comienzo muchos picos que después desaparecen.
Creo que, al empezar a entrenar antes de terminar de construir el dataset, cuando "toca" un batch con samples nuevos (que no ha visto mucho la
red) tiene un alto error, que se corresponden con esos picos. Una vez que ya ha terminado de completarse y entrenar sobre el dataset completo,
desaparecen los picos.
>> Creo que estoy significa que la red hace overfitting: obtiene poco error con los elementos (samples) que ya ha visto (y entrenado y hecho
overfitting sobre ellos) pero cuando ve elementos nuevos obtiene un alto error porque no es capaz de generalizar bien. Después, desaparecen
los picos una vez que ya ha entrenado (y hecho overfitting) sobre todos los samples -> ya no hay samples nuevos que provoquen picos en el error.

------- Experimentos a realizar

> Hacer que el TD target no varíe cada iteración, sino que se usen los "pesos antiguos" y se actualicen cada X iteraciones.

> Intentar evitar el overfitting -> aumentar dropout, bajar número de repeticiones en cada iteración, bajar tasa de aprendizaje, 
aumentar tamaño de batch

> Para crearme un conjunto de "validación" podría guardar un replay buffer de samples que no ve la red (pero que contienen planes de los
niveles de entrenamiento) y calcular el loss en ese dataset cada cierto tiempo.

-------- Resultados Pruebas (validación)

Nota: cada iteración se corresponde con cuatro iteraciones del descenso de gradientes, cada una con un minibatch distinto

Número de acciones para completar cada nivel de validación  -  Suma

> DQmodel_fixed_q_targets_tau-200_step-500_4.ckpt  - 60 y 71 - 131
> DQmodel_fixed_q_targets_tau-200_step-500_5.ckpt  - 66 y 70 - 136

> DQmodel_fixed_q_targets_tau-200_step-1000_4.ckpt - 64 y 68 - 132
> DQmodel_fixed_q_targets_tau-200_step-1000_5.ckpt - 69 y 81 - 150

- Menor alfa -> empeora el resultado y reduce un poco el overfitting

> DQmodel_fixed_q_targets_tau-250_alfa-0.001_500_2.ckpt - 51 y 90 - 141
> DQmodel_fixed_q_targets_tau-250_alfa-0.001_1000_1.ckpt - 55 y 79 - 134

> DQmodel_fixed_q_targets_tau-250_alfa-0.001_500_2.ckpt - 70 y 85 - 155
> DQmodel_fixed_q_targets_tau-250_alfa-0.001_1000_2.ckpt - 77 y 81 - 158

- Mayor alfa -> peores resultados con 500 aunque reduce mucho el overfitting

> DQmodel_fixed_q_targets_tau-250_alfa-0.01_500_1.ckpt - 68 y 101 - 169
> DQmodel_fixed_q_targets_tau-250_alfa-0.01_1000_1.ckpt - 43 y 87 - 130

- Menos repeticiones por sample (2)

> DQmodel_fixed_q_targets_tau-250_alfa-0.005_num-rep-2_500_2.ckpt - 49 y 70 - 119 -> Tam dataset = 1000
> DQmodel_fixed_q_targets_tau-250_alfa-0.005_num-rep-2_1000_2.ckpt" - 58 y 68 - 126 -> Tam dataset = 2000

  LOG_IT COINCIDE CON EL TAMAÑO DEL DATASET. SOLO SE AUMENTA EN LA PRIMERA REPETICIÓN.

  Este último también empeora cuando aumenta el número de repeticiones (tamaño del dataset). Sin embargo,
  realiza 1000 * 2 repeticiones = 2000 iteraciones totales, el mismo número que el mejor modelo de 500
  (500 * 4 repeticiones = 2000 iteraciones totales). Este modelo obtiene 126 de puntuación mientras que
  el otro obtiene 131. Esto quiere decir que sigue haciendo overfitting, pero que el modelo funciona bien
  (<<el mismo número de repeticiones en un dataset más grande (1000 ejemplos) obtiene mejores resultados>>).

  Debería probar con solo una repetición, o incluso una repetición por cada dos iteraciones del act.

- 1 Repetición por sample

> DQmodel_fixed_q_targets_tau-250_alfa-0.005_num-rep-1_1.ckpt

Num it:            Suma
100		60 y 120 - 180
250	    75 y 88  - 163
500     67 y 94  - 161
1000    71 y 77  - 148
2000    68 y 76  - 144
3000    56 y 74  - 130
4000    54 y 73  - 127
5000    42 y 73  - 115 
6000    42 y 64  - 106 <----- 6000 es el mejor número de iteraciones!
7000    56 y 64  - 120 Overfitting!
8000	42 y 77  - 119
9000    42 y 89  - 131

> DQmodel_fixed_q_targets_tau-250_alfa-0.005_num-rep-1_2.ckpt

Num it:            Suma
100		98 y 107 - 205
250	    77 y 97  - 174
500     70 y 105 - 175
1000    79 y 80  - 159
2000    47 y 86  - 133
3000    73 y 86  - 159
4000    57 y 75  - 132
5000    54 y 75  - 129 
6000    48 y 74  - 122 <----- 6000 mejor num it!
7000    61 y 77  - 138
8000	59 y 69  - 128
9000    52 y 76  - 128
10000   49 y 87  - 136

<Parece que 6000 iteraciones es el mejor número>

Conclusión: se sigue produciendo overfitting, aunque parece que un poco menos.
Debería probar a ejecutar el mismo número de iteraciones independientemente del tamaño
del dataset.
Probar también a disminuir la tasa de aprendizaje, especialmente a usar exponential decay.