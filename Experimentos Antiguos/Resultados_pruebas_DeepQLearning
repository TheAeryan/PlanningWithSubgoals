Resultados del modelo greedy (no Q-Learning)

- Batch=16, start_size=0, alfa=0.002, num_rep=4
> Tamaño del dataset: 1500 elementos - Tiempo usado: 20 minutos
> Loss al final: 17.5

----------- Número de acciones usadas para completar cada nivel del validation dataset
- 71 y 72 acciones


----------- Modelo Deep Q-Learning

Tarda mucho en ejecutar el entrenamiento (creo que porque tiene que calcular el min q-value de los estados del experience replay)

- Mejor número de repeticiones: 4 (funciona más o menos igual que 8 pero con datasets más grandes (lo que es mejor))

- Mejor número de filtros: 4

- Mejor número de unidades: 128 (256 no aporta casi nada de mejora)

>> Mejor arquitectura (por ahora): 4_filters, units=[64, 16], alfa=0.005, 4_repeticiones -> También muy estable entre varias runs

>> 2ª mejor arquitectura: 4_filters, units=[128, 16], alfa=0.005, 4_repeticiones -> Muy parecida a la anterior

- Padding = Valid da muy malos resultados

- Dos capas convolucionales dan muy malos resultados

- Es mejor usar dropout

--------- Validación -----------------------

- Arquitectura: 4_filtros, units=[64, 16], num_rep=4, alfa=0.005, save_step=575 (número de iteraciones ~ tamaño dataset = <591 samples>)
>> Número de acciones para completar los niveles: 65 y 69 -> suma = 134

---- Tras solucionar problema dropout

--- Arquitectura: S2-drop-sol, 4_filtros, units=[64, 16], num_rep=4, alfa=0.005, dropout=0.4, save_step=575
>>> Número de acciones 1: 60 y 72 -> suma = 132
>>> Número de acciones 2: 59 y 67 -> suma = 126 (S3-drop-sol, 4_filtros, units=[64, 16], num_rep=4, alfa=0.005, dropout=0.4, save_step=575, 1500)
>>> Número de acciones 3: 57 y 76 -> suma = 133 (Arquitectura final F1)
>>> Número de acciones 4: 67 y 84 -> suma = 151 (Arquitectura final F2)
 --- 1500 iteraciones -> EMPEORA EL RESULTADO AL AUMENTAR EL NÚMERO DE EJEMPLOS DE ENTRENAMIENTO (OVERFITTING POR EJECUTAR MÁS ITERACIONES??)
>>> Número de acciones 1: 94 y 96 -> suma = 190 (Arq. F1)
>>> Número de acciones 2: 72 y 100 -> suma = 172 (Arq. F2)
 --- 3000 iteraciones
>>> Número de acciones 2: 50 y 93 -> suma = 143 (Arq. F2)

- Arquitectura: S5-drop-sol, 4_filtros, units=[32, 8], num_rep=4, alfa=0.005, dropout=0.4, save_step=575
>> Núm acciones: 74 y 87 (MUY MAL RESULTADO)

- Arquitectura: S2-drop-sol, 4_filtros, units=[128, 16], num_rep=4, alfa=0.005, dropout=0.4, save_step=575, 1500 (el archivo es el _1)
>> Num acciones: 82 y 90 (MUY MAL RESULTADO)

- Arquitectura: S1-drop-sol, 4_filtros, units=[64, 8], num_rep=4, alfa=0.005, dropout=0.4, save_step=575, 1500
>> Num acciones: 75 y 77

- Arquitectura: S1-drop-sol, 4_filtros, units=[100], num_rep=4, alfa=0.005, dropout=0.4, save_step=575, 1500
>> Num acciones: 62 y 76 -> suma = 138

