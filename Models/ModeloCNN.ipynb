{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.metrics import mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -Training Dataset-\n",
    "dataset = np.load('datasets/dataset_train_3.npz')\n",
    "dataset_x = dataset['X']\n",
    "dataset_y = dataset['Y']\n",
    "\n",
    "# -Validation Dataset-\n",
    "test_dataset = np.load(\"datasets/dataset_test.npz\") \n",
    "test_dataset_x = test_dataset['X']\n",
    "test_dataset_y = test_dataset['Y']\n",
    "test_dataset_y_resh = np.reshape(test_dataset_y, (-1, 1)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN:\n",
    "\n",
    "    def __init__(self, name=\"CNN\", writer_name=\"CNN\",\n",
    "                 l1_num_filt = 16, l1_window = [4,4], l1_strides = [1,1],\n",
    "                 l2_num_filt = 32, l2_window = [2,2], l2_strides = [1,1],\n",
    "                 padding_type = \"VALID\",\n",
    "                 fc_num_units = 256):\n",
    "        \n",
    "        with tf.variable_scope(name):\n",
    "            # Batch of inputs (game states, one-hot encoded)\n",
    "            self.X = tf.placeholder(tf.float32, [None, 13, 26, 9], name=\"X\") # type tf.float32 is needed for the rest of operations\n",
    "\n",
    "            # Batch of outputs (correct predictions of number of actions)\n",
    "            self.Y_corr = tf.placeholder(tf.float32, [None, 1], name=\"Y\")\n",
    "\n",
    "\n",
    "            \"\"\"\n",
    "            First convnet:\n",
    "            \"\"\"\n",
    "            \n",
    "            # Padding = \"VALID\" -> no padding, \"SAME\" -> padding to keep the output dimension the same as the input one\n",
    "            \n",
    "            self.conv1 = tf.layers.conv2d(inputs = self.X,\n",
    "                                         filters = l1_num_filt,\n",
    "                                         kernel_size = l1_window,\n",
    "                                         strides = l1_strides,\n",
    "                                         padding = padding_type,\n",
    "                                         activation = tf.nn.relu,\n",
    "                                         use_bias = True,\n",
    "                                         kernel_initializer=tf.contrib.layers.xavier_initializer_conv2d(),\n",
    "                                         name = \"conv1\")\n",
    "   \n",
    "            \"\"\"\n",
    "            Second convnet:\n",
    "            \"\"\"\n",
    "    \n",
    "            self.conv2 = tf.layers.conv2d(inputs = self.conv1,\n",
    "                                         filters = l2_num_filt,\n",
    "                                         kernel_size = l2_window,\n",
    "                                         strides = l2_strides,\n",
    "                                         padding = padding_type,\n",
    "                                         activation = tf.nn.relu,\n",
    "                                         use_bias = True,\n",
    "                                         kernel_initializer=tf.contrib.layers.xavier_initializer_conv2d(),\n",
    "                                         name = \"conv2\")        \n",
    "            \n",
    "            # Flatten output of conv layers\n",
    "            \n",
    "            self.flatten = tf.contrib.layers.flatten(self.conv2)\n",
    "            \n",
    "            # Fully connected layer\n",
    "            \n",
    "            self.fc = tf.layers.dense(inputs = self.flatten,\n",
    "                                  units = fc_num_units,\n",
    "                                  activation = tf.nn.relu,\n",
    "                                  kernel_initializer=tf.contrib.layers.xavier_initializer(),\n",
    "                                  name=\"fc\")\n",
    "            \n",
    "            # Output Layer\n",
    "            \n",
    "            self.output = tf.layers.dense(inputs = self.fc, \n",
    "                                          kernel_initializer=tf.contrib.layers.xavier_initializer(),\n",
    "                                          units = 1, \n",
    "                                          activation=None)\n",
    "            \n",
    "            # Train\n",
    "            \n",
    "            self.loss = tf.reduce_mean(tf.square(self.output - self.Y_corr), name=\"loss\") # Quadratic loss\n",
    "            \n",
    "            self.optimizer = tf.train.AdamOptimizer(learning_rate=0.001, name=\"optimizer\")\n",
    "            self.train_op = self.optimizer.minimize(self.loss, name=\"train_op\")\n",
    "            \n",
    "            # Summaries\n",
    "            self.train_loss_sum = tf.summary.scalar('train_loss', self.loss) # Training loss\n",
    "            self.test_loss_sum = tf.summary.scalar('test_loss', self.loss) # Validation loss\n",
    "            \n",
    "            self.writer = tf.summary.FileWriter(\"ModeloCNN_log/\" + writer_name)\n",
    "            self.writer.add_graph(tf.get_default_graph())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "CNN_test = CNN(name=\"CNN\", writer_name=\"CNN_l1_(n=4,w=4,s=4)_l2_(n=8,w=2,s=2)_pad=V_fc_units=32\",\n",
    "               l1_num_filt = 4, l1_window = [4,4], l1_strides = [4,4],\n",
    "               l2_num_filt = 8, l2_window = [2,2], l2_strides = [2,2],\n",
    "               padding_type = \"VALID\",\n",
    "               fc_num_units = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "---MAE TRAIN---\n",
      "\n",
      "\n",
      "Model: 5.376889455714331\n",
      "Baseline: 6.7887650132224895\n",
      "\n",
      "\n",
      "---MAE VALIDATION--\n",
      "\n",
      "\n",
      "Model: 7.513050222279691\n",
      "Baseline: 7.099567260502611\n"
     ]
    }
   ],
   "source": [
    "# Number of epochs\n",
    "num_epochs = 150\n",
    "# Minibatch size\n",
    "batch_size = 128\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer()) # Initialize all variables\n",
    "    \n",
    "    #output = sess.run(CNN_test.output, feed_dict={CNN_test.X:test_dataset_x, CNN_test.Y_corr:test_dataset_y_resh})\n",
    "    #print(output)\n",
    "    \n",
    "    rkf = RepeatedKFold(n_splits=int(len(dataset_y) // batch_size),\n",
    "                      n_repeats=num_epochs) # Get randomized indexes for minibatches\n",
    "\n",
    "    # Feed Dict for validation (uses validation set)\n",
    "    data_dict_test = {CNN_test.X:test_dataset_x, CNN_test.Y_corr:test_dataset_y_resh}\n",
    "        \n",
    "    # Train the model\n",
    "        \n",
    "    it = 0\n",
    "        \n",
    "    for _, batch_index in rkf.split(dataset_y):\n",
    "        batch_x = np.take(dataset_x, batch_index, axis=0) # Obtain current training batch\n",
    "        batch_y = np.take(dataset_y, batch_index)\n",
    "        batch_y = np.reshape(batch_y, (-1, 1))\n",
    "            \n",
    "        data_dict = {CNN_test.X:batch_x, CNN_test.Y_corr:batch_y}\n",
    "           \n",
    "        sess.run(CNN_test.train_op, feed_dict=data_dict) # Execute one training step\n",
    "            \n",
    "        # Periodically check losses\n",
    "        if it % 5 == 0:                \n",
    "            sum1 = sess.run(CNN_test.test_loss_sum, feed_dict=data_dict_test)\n",
    "            CNN_test.writer.add_summary(sum1, it)\n",
    "            sum2 = sess.run(CNN_test.train_loss_sum, feed_dict=data_dict)\n",
    "            CNN_test.writer.add_summary(sum2, it)   \n",
    "\n",
    "        it += 1\n",
    "    \n",
    "    # --- After training ---\n",
    "        \n",
    "    # Compute MAE\n",
    "            \n",
    "    dataset_y_reshaped = np.reshape(dataset_y, (-1, 1))   \n",
    "    data_dict = {CNN_test.X:dataset_x}\n",
    "        \n",
    "    y_pred = sess.run(CNN_test.output, feed_dict=data_dict)\n",
    "        \n",
    "    mae_base = mean_absolute_error(dataset_y, np.repeat(np.mean(dataset_y), dataset_y.shape[0]))\n",
    "    mae_model = mean_absolute_error(dataset_y, y_pred)\n",
    "        \n",
    "    print(\"\\n\\n---MAE TRAIN---\\n\\n\")\n",
    "    print(\"Model:\", mae_model)\n",
    "    print(\"Baseline:\", mae_base)\n",
    "        \n",
    "    # ----- VALIDATION -----\n",
    "\n",
    "    # Compute predictions\n",
    "    data_dict = {CNN_test.X:test_dataset_x}\n",
    "    test_pred = sess.run(CNN_test.output, feed_dict=data_dict)\n",
    "        \n",
    "    mae_base_test = mean_absolute_error(test_dataset_y, np.repeat(np.mean(dataset_y), test_dataset_y.shape[0]))\n",
    "    mae_model_test = mean_absolute_error(test_dataset_y, test_pred)\n",
    "        \n",
    "    print(\"\\n\\n---MAE VALIDATION--\\n\\n\")\n",
    "    print(\"Model:\", mae_model_test)\n",
    "    print(\"Baseline:\", mae_base_test)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
